# ğŸ›¡ï¸ Task-5: Monitoring & Alerting with Prometheus + Alertmanager

This task implements real-time monitoring and alerting for the Wearipedia Fitbit data pipeline using **Prometheus** and **Alertmanager**. This setup ensures that key system metrics can be observed and alerts can be triggered on abnormal behavior, such as data pipeline stalls, ingestion failure, or custom metric thresholds.

---

## ğŸ“¦ Components

### ğŸ” Prometheus
- Scrapes metrics from the FastAPI application and other services.
- Uses `prometheus.yml` configuration to discover targets.
- Exposes a dashboard at **http://localhost:9090**.

### ğŸš¨ Alertmanager
- Handles alerts triggered by Prometheus.
- Configured to send **email alerts** using environment-specific SMTP credentials.
- Accessible at **http://localhost:9093**.

---

## âš™ï¸ Configuration Files

### `prometheus.yml`
Defines scrape intervals, targets (such as `api`, `metrics.py` exporter), and alert rules:
```yaml
scrape_configs:
  - job_name: 'api'
    static_configs:
      - targets: ['api:8000']

  - job_name: 'custom-metrics'
    static_configs:
      - targets: ['metrics:8001']

ğŸ–¼ï¸ Dashboard Screenshots

âœ… Prometheus Dashboard

![alt text](image.png)

âš ï¸ Alertmanager Dashboard

![alt text](image-1.png)

Prometheus pulls this data every 15 seconds to evaluate alert rules.

ğŸš€ Running the Stack
### 1. Start Prometheus and Alertmanager
```bash
docker-compose up -d prometheus alertmanager
```
### 2. Verify dashboards:

	â€¢ Prometheus: http://localhost:9090
	â€¢ Alertmanager: http://localhost:9093


âœ… Design Decisions
	â€¢ Separation of metrics server (metrics.py) ensures Prometheus can scrape independently of the main API.
	â€¢ SMTP credentials are loaded via .env to support secure deployment.
	â€¢ rules.yml is modular and can be extended with custom thresholds per metric (e.g., abnormal HRV values).
	â€¢ Prometheus + Alertmanager combo gives high observability at minimal infrastructure cost.

ğŸ“ Directory Structure
Task-5/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ prometheus.yml
â”œâ”€â”€ alertmanager.yml
â”œâ”€â”€ rules.yml
â””â”€â”€ metrics.py

ğŸ“Œ Improvements Possible
	â€¢ Add Grafana dashboards for richer visualization.
	â€¢ Integrate Slack or PagerDuty for more advanced alerting.
	â€¢ Auto-scaling alerts based on CPU/memory usage via node_exporter.

â¸»

ğŸ§  Summary

This monitoring stack plays a crucial role in operational excellence by:
	â€¢ Ensuring real-time visibility of ingestion performance.
	â€¢ Alerting engineers proactively on failure.
	â€¢ Laying groundwork for production-grade observability.